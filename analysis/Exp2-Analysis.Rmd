---
title: "Exp2-Analysis"
author: "Josh White"
date: "07/02/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, cache = TRUE, message = FALSE)

library(tidyverse)
library(here)
library(car) 
library(brms)
library(skimr)
library(qpcR) #for aikake.weights()
library(fitdistrplus) # for statistical plots and tests for fitting distributions
library(lm.beta)
```

# Introductory Steps

## Load Packages and set seed for reproducibility

```{r load-packages, eval = FALSE}
library(tidyverse)
library(here)
library(car) 
library(brms)
library(skimr)
library(qpcR) #for aikake.weights()
library(fitdistrplus) # for statistical plots and tests for fitting distributions
library(lm.beta)

set.seed(1298)
```

## Import Data

```{r import-data, warning = FALSE}
data <- read_csv("parsedrawresultsexp2.csv", col_types = "icffffiiiiiififc")
data <- data[,2:ncol(data)]
data <- data %>% filter(age != 99) #remove amy test from dataset
data

#load previous data
load("exp1d.Rda")

# get means for each vignette
meanAAdata <- exp1d %>% group_by(vignetteType, vignetteNumber) %>% summarise(meanAA = mean(vignetteAnswer))
meanAAdata

```

## Data Wrangling

```{r wrangle}
## mutate to get Oddsfav for each participant
data <- data %>% mutate(oddsFav = vignetteXprob/vignetteYprob)

# Y is favourable outcome in Loss vignettes, so take inverse
data$oddsFav[data$vignetteType == "L"] <- 1/data$oddsFav[data$vignetteType == "L"] 

## mutate to get differences between options 
data <- data %>% mutate(fav_minus_unfav = vignetteXprob - vignetteYprob)
data$fav_minus_unfav[data$vignetteType == "L"] <- -(data$fav_minus_unfav[data$vignetteType == "L"]) # opposite sign for losses cause Y is favourable

# create vignette column
order <- c(sprintf("G%d", seq(1:12)), sprintf("L%d", seq(1:12))) 
data$vignette <- paste0(data$vignetteType, data$vignetteNumber) %>% factor(levels = order)

```

### exclude participants

```{r exclude}
#check whether observations fail instruction checks
instr_fail <- data$postQuestion1 == "incorrect" | data$dummyXprob <= 50

#remove data from main dataset and save for possible later analysis (was a particular question more confusing etc?)
d_removed <- data[instr_fail,]
d_pass <- data[!instr_fail,]

d_removed
d_pass

```

### Get final dataset for regression models.

```{r datawrangle}

## summarise data to get mean Odds and meanCR
d <- d_pass %>% group_by(vignetteType, vignetteNumber, vignette) %>% summarise(meanOddsFav = mean(oddsFav),
                                                                               meanpercdiff = mean(fav_minus_unfav),
                                                                                meanCR = mean(vignetteConfidence))
d <- left_join(d, meanAAdata, by = c("vignetteType", "vignetteNumber"))

#reorder
d <- d[c(1, 3:7)]
d

```

# ANALYSIS USING PERCENTAGE DIFFERENCE

## plot and descriptives
```{r plot-diff}
ggplot(d_pass, aes(x = vignette, y = fav_minus_unfav, fill = vignetteType)) + 
  geom_jitter(width = 0.20, height = 0) +
  stat_summary(fun.y=mean, geom="bar", alpha = 0.8)

skim(d_pass)

```

## Models

### Frequentist

```{r mods-freq-diff}
mods.diff <- list()

#models for AA with mean percent difference
mods.diff[[1]] <- lm(meanAA ~ 1, data = d)
mods.diff[[2]] <- lm(meanAA ~ vignetteType + 1, data = d)
mods.diff[[3]] <- lm(meanAA ~ meanpercdiff + vignetteType + 1, data = d)
mods.diff[[4]] <- lm(meanAA ~ meanpercdiff*vignetteType + 1, data = d)

## compare model fit with AIC/BIC and AIC/BIC weights. 
AICs.diff <- map_dbl(mods.diff, AIC)
BICs.diff <- map_dbl(mods.diff, BIC)
AICw.diff <- akaike.weights(AICs.diff)
BICw.diff <- akaike.weights(BICs.diff)

# Both BIC and AIC point to model 3 as best fitting (percdiff and vignette type with no interaction)
AICs.diff
AICw.diff
BICs.diff 
BICw.diff

# check assumptions of models -- no violations. 
map(mods.diff, function(x){plot(fitdist(x$residuals, distr = "norm"))})

mods.conf <- list()

#models using confidence rating
mods.conf[[1]] <- lm(meanAA ~ meanCR + 1, data = d)
mods.conf[[2]] <- lm(meanAA ~ meanCR + vignetteType + 1, data = d)
mods.conf[[3]] <- lm(meanAA ~ meanCR*vignetteType + 1, data = d)

AICs.conf <- map_dbl(mods.conf, AIC)
BICs.conf <- map_dbl(mods.conf, BIC)
AICw.conf <- akaike.weights(AICs.conf)
BICw.conf <- akaike.weights(BICs.conf)

# Both BIC and AIC point to model 2 as best fitting
AICs.conf
AICw.conf
BICs.conf 
BICw.conf

# check assumptions of models -- no violations. 
map(mods.conf, function(x){plot(fitdist(x$residuals, distr = "norm"))})

## Get details for best models and combine to see if it improves. 

#diff model
summary(mods.diff[[3]])

#conf model
summary(mods.conf[[2]]) # confidence does not help prediction.

##combine best fitting models as per pre-registration.
mod.combined <- lm(meanAA ~ meanpercdiff + meanCR + vignetteType + 1, data = d)
summary(mod.combined)

#compare combined and original model
AICs <- c(AIC(mod.combined), AIC(mods.diff[[3]]), AIC(mods.conf[[2]]))
AICw <- akaike.weights(AICs)

AICs
AICw

##  percent difference model preferred
mods.diff[[3]] %>% lm.beta() %>% summary()

## draw graph
d %>% ggplot(aes(x = meanpercdiff, y = meanAA, col = vignetteType)) + 
  geom_text(aes(label = vignette)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Mean percentage difference (fav - unfav) ") +
  ylab("Mean ambiguity aversion rating")
  

mod.scaledAA <- lm(scale(meanAA) ~ meanpercdiff + vignetteType + 1, data = d)
summary(mod.scaledAA)
```

## Bayesian

``` {r bayes-mod-diff, warning = FALSE}
bayesmods.diff <- list()

bayesmods.diff[[1]] <- brm(meanAA ~ 1, data = d, refresh = 0, open_progress = FALSE)
bayesmods.diff[[2]] <- brm(meanAA ~ vignetteType + 1, data = d, refresh = 0,open_progress = FALSE)
bayesmods.diff[[3]] <- brm(meanAA ~ vignetteType + 1, data = d, refresh = 0,open_progress = FALSE)
bayesmods.diff[[4]] <- brm(meanAA ~ meanpercdiff*vignetteType + 1, data = d, refresh = 0,open_progress = FALSE)

bayesmods.conf <- list()

bayesmods.conf[[1]] <- brm(meanAA ~ meanCR + 1, data = d, refresh = 0,open_progress = FALSE)
bayesmods.conf[[2]] <- brm(meanAA ~ meanCR + vignetteType + 1, data = d, refresh = 0,open_progress = FALSE)
bayesmods.conf[[3]] <- brm(meanAA ~ meanCR*vignetteType + 1, data = d, refresh = 0,open_progress = FALSE)

#compare diff models
bayesmods.diff <- map(bayesmods.diff, add_waic) # Add WAIC to brms object
bayes.diff.comparison <- loo_compare(bayesmods.diff[[1]], bayesmods.diff[[2]], 
                                    bayesmods.diff[[3]], bayesmods.diff[[4]], criterion = "waic") # compare models
bayes.diff.comparison 

#compare conf models
bayesmods.conf <- map(bayesmods.conf, add_waic) # Add WAIC to brms object
bayes.conf.comp <- loo_compare(bayesmods.conf[[1]], bayesmods.conf[[2]], 
                               bayesmods.conf[[3]], criterion = "waic") # compare models
bayes.conf.comp

## Get details for best models and combine to see if it improves. 

#diff model
summary(bayesmods.diff[[3]])

#conf model
summary(bayesmods.conf[[2]])

##combine models to one. 
bayesmod.combined <- brm(meanAA ~ meanpercdiff + meanCR + vignetteType + 1, data = d, refresh = 0, open_progress = FALSE)
bayesmod.combined <- add_waic(bayesmod.combined)
summary(bayesmod.combined)

loo_compare(bayesmod.combined, bayesmods.diff[[3]], criterion = "waic")

## combined model not preffered. 
## model with gain/loss and perc diff the best

summary(bayesmods.diff[[3]])
plot(bayesmods.diff[[3]])

```

# PREREGISTERED ANALYSIS USING ODDS

## Remove all undefined values from dataframe
. 
```{r remove-inf}
d_prereg <- d_pass[d_pass$fav_minus_unfav != 100 & d_pass$fav_minus_unfav != 100,] # cause this gives undefined odds or 0 odds (depending on which is numerator)

d.pr <- d_prereg %>% group_by(vignetteType, vignetteNumber, vignette) %>% summarise(meanOddsFav = mean(oddsFav),
                                                                               meanpercdiff = mean(fav_minus_unfav),
                                                                                meanCR = mean(vignetteConfidence))
d.pr <- left_join(d.pr, meanAAdata, by = c("vignetteType", "vignetteNumber"))

#reorder
d.pr <- d.pr[c(1, 3:7)]
d.pr

```

## plot and descpriptive stats

```{r plot-odds}

## graph odds by vignette
ggplot(d_prereg, aes(x = vignette, y = oddsFav - 1, fill = vignetteType)) + 
  geom_jitter(width = 0.20, height = 0) +
  stat_summary(fun.y=mean, geom="bar", alpha = 0.8) +
   scale_y_continuous(breaks=seq(-1, 98, 10), labels=seq(0,99,10)) + 
  ylab("Odds of favourable outcome") 
# note, -1  and labels in order to move origin of bars to 1. 

##now remove individual data points to better see averages.
ggplot(d_prereg, aes(x = vignette, y = oddsFav - 1, fill = vignetteType)) +
  stat_summary(fun.y=mean, geom="bar", alpha = 0.8) +
   scale_y_continuous(breaks=seq(-1, 5, 1), labels=seq(0,6,1)) + 
  ylab("Odds of favourable outcome") 

skim(d_prereg)

```

## Models

### Frequentist

```{r mods-freq-odds}
mods.odds.pr <- list()

#models for AA with mean percent difference
mods.odds.pr[[1]] <- lm(meanAA ~ 1, data = d.pr)
mods.odds.pr[[2]] <- lm(meanAA ~ vignetteType + 1, data = d.pr)
mods.odds.pr[[3]] <- lm(meanAA ~ meanOddsFav + vignetteType + 1, data = d.pr)
mods.odds.pr[[4]] <- lm(meanAA ~ meanOddsFav*vignetteType + 1, data = d.pr)

## compare model fit with AIC/BIC and AIC/BIC weights. 
AICs.odds.pr <- map_dbl(mods.odds.pr, AIC)
BICs.odds.pr <- map_dbl(mods.odds.pr, BIC)
AICw.odds.pr <- akaike.weights(AICs.odds.pr)
BICw.odds.pr <- akaike.weights(BICs.odds.pr)

# Both BIC and AIC point to model 2 as best fitting (percdiff and vignette type with no interaction)
AICs.odds.pr
AICw.odds.pr
BICs.odds.pr 
BICw.odds.pr

# check assumptions of models -- no violations. 
map(mods.odds.pr, function(x){plot(fitdist(x$residuals, distr = "norm"))})


mods.conf.pr <- list()

#models using confidence rating
mods.conf.pr[[1]] <- lm(meanAA ~ meanCR + 1, data = d.pr)
mods.conf.pr[[2]] <- lm(meanAA ~ meanCR + vignetteType + 1, data = d.pr)
mods.conf.pr[[3]] <- lm(meanAA ~ meanCR*vignetteType + 1, data = d.pr)

AICs.conf.pr <- map_dbl(mods.conf, AIC)
BICs.conf.pr <- map_dbl(mods.conf, BIC)
AICw.conf.pr <- akaike.weights(AICs.conf)
BICw.conf.pr <- akaike.weights(BICs.conf)

# Both BIC and AIC point to model 2 as best fitting (percdiff and vignette type with no interaction)
AICs.conf.pr
AICw.conf.pr
BICs.conf.pr
BICw.conf.pr

# check assumptions of models -- no violations. 
map(mods.conf.pr, function(x){plot(fitdist(x$residuals, distr = "norm"))})

## Get details for best models and combine to see if it improves. 

#diff model
summary(mods.odds.pr[[2]])

#conf model
summary(mods.conf.pr[[2]]) # confidence does not help prediction.

##combine best fitting models as per pre-registration.
mod.combined.pr <- lm(meanAA ~ meanCR + vignetteType + 1, data = d.pr)
summary(mod.combined.pr)

#compare combined and original model
AICs.pr <- c(AIC(mod.combined.pr), AIC(mods.odds.pr[[2]]), AIC(mods.conf.pr[[2]]))
AICw.pr <- akaike.weights(AICs)

AICs.pr
AICw.pr

##  percent difference model preferred
mods.odds.pr[[3]] %>% lm.beta() %>% summary()

## draw graph
d.pr %>% ggplot(aes(x = meanOddsFav, y = meanAA, col = vignetteType)) + 
  geom_text(aes(label = vignette)) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Mean Odds of Favourable event") +
  ylab("Mean ambiguity aversion rating")

mod.scaledAA.pr <- lm(scale(meanAA) ~ meanOddsFav + vignetteType + 1, data = d.pr)
summary(mod.scaledAA.pr)

```

### Bayesian

``` {r bayes-mod-odds}
bayesmods.odds.pr <- list()

bayesmods.odds.pr[[1]] <- brm(meanAA ~ 1, data = d.pr, refresh = 0, open_progress = FALSE)
bayesmods.odds.pr[[2]] <- brm(meanAA ~ vignetteType + 1, data = d.pr, refresh = 0, open_progress = FALSE)
bayesmods.odds.pr[[3]] <- brm(meanAA ~ meanOddsFav + vignetteType + 1, data = d.pr, refresh = 0, open_progress = FALSE)
bayesmods.odds.pr[[4]] <- brm(meanAA ~ meanOddsFav*vignetteType + 1, data = d.pr, refresh = 0, open_progress = FALSE)

bayesmods.conf.pr <- list()

bayesmods.conf.pr[[1]] <- brm(meanAA ~ meanCR + 1, data = d.pr, refresh = 0, open_progress = FALSE)
bayesmods.conf.pr[[2]] <- brm(meanAA ~ meanCR + vignetteType + 1, data = d.pr, refresh = 0, open_progress = FALSE)
bayesmods.conf.pr[[3]] <- brm(meanAA ~ meanCR*vignetteType + 1, data = d.pr, refresh = 0, open_progress = FALSE)

#compare diff models
bayesmods.odds.pr <- map(bayesmods.odds.pr, add_waic) # Add WAIC to brms object
bayes.odds.comparison.pr <- loo_compare(bayesmods.odds.pr[[1]], bayesmods.odds.pr[[2]], 
                                    bayesmods.odds.pr[[3]], bayesmods.odds.pr[[4]], criterion = "waic") # compare models
bayes.odds.comparison.pr 

#compare conf models
bayesmods.conf.pr <- map(bayesmods.conf.pr, add_waic) # Add WAIC to brms object
bayes.conf.comp.pr <- loo_compare(bayesmods.conf.pr[[1]], bayesmods.conf.pr[[2]], 
                               bayesmods.conf.pr[[3]], criterion = "waic") # compare models
bayes.conf.comp.pr

## Get details for best models and combine to see if it improves. 

#odds model
summary(bayesmods.odds.pr[[3]])

#conf model
summary(bayesmods.conf.pr[[2]])

##combine models to one. 
bayesmod.combined.pr <- brm(meanAA ~ meanOddsFav + meanCR + vignetteType + 1, data = d.pr, refresh = 0, open_progress = FALSE)
bayesmod.combined.pr <- add_waic(bayesmod.combined.pr)
summary(bayesmod.combined.pr)

loo_compare(bayesmod.combined.pr, bayesmods.odds.pr[[3]], criterion = "waic")

## combined model not preffered. 
## model with gain/loss and perc diff the best

summary(bayesmods.odds.pr[[3]])
plot(bayesmods.odds.pr[[3]])

```
