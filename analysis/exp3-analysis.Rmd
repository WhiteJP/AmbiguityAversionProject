---
title: "Experiment 3 Main Analysis"
author: "Josh White"
date: "03/01/2022"
output: 
  html_document:
    df_print: paged
    theme: journal
    code_folding: hide
    toc: true
    toc_depth: 4
    toc_float:
        collapsed: false
        smooth_scroll: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = TRUE)

options(
  tidyverse.quiet = TRUE,
  digits = 2,
  fig.width = 5, 
  fig.heigt = 7
)

library(tidyverse)
library(here)

# Visualization
library(ggsci)
library(ggrepel)
library(moderndive) # for geom_parallel_slopes_function because there is no way to do this in 

# Modeling
library(lme4)
library(ordinal) # for clmm function
library(brms) # for Bayesian analyses

# Tables
library(flextable)
library(ftExtra)

theme_set(theme_classic())

set.seed(683)

# Get logicals for whether Bayesian models have been run
LTFUmods_exist <- fs::file_exists("bayesmods_LTFU.Rdata")
priormods_exist <- fs::file_exists("bayesmods_prior.Rdata")
confmods_exist <- fs::file_exists("bayesmods_conf.Rdata")
combmods_exist <- fs::file_exists("bayesmods_comb.Rdata")
```

# Introductory Steps {.tabset .tabset-pills}

## Load packages and set seed

```{r load-packages, eval = FALSE, class.source = "fold-show"}
library(tidyverse)
library(here)

# Visualization
library(ggsci)
library(ggrepel)
library(moderndive) # for geom_parallel_slopes_function because there is no way to do this in 

# Modeling
library(lme4)
library(ordinal) # for clmm function
library(brms) # for Bayesian analyses

# Tables
library(flextable)
library(ftExtra)

# set ggplot theme
theme_set(theme_classic())

#set seed
set.seed(683)

# Get logicals for whether Bayesian models have been run
LTFUmods_exist <- fs::file_exists("bayesmods_LTFU.Rdata")
priormods_exist <- fs::file_exists("bayesmods_prior.Rdata")
confmods_exist <- fs::file_exists("bayesmods_conf.Rdata")
combmods_exist <- fs::file_exists("bayesmods_comb.Rdata")

```

## Import and wrangle data

Import data from both timepoints, join together, recode variables etc. 

```{r import-data, warning = FALSE}
# get subject mapping
subj_map <- read_csv(
  here::here("experiment3", "subjectID-mapping.csv"),
  na = c("", "NA", "na")
  )

#Get timepoint1 data
da <- read_csv(
  here::here("experiment3", "timepoint1", "data", "exp3a-data.csv"),
  na = c("", "NA", "na")
  )

da <- da %>% 
  left_join(subj_map, by = c("subject" = "part1code"))

#WRANGLE 3A

#make factors 
da <- da %>% 
  mutate(
    gender = factor(gender),
    income = factor(income, levels = c("<20k", "20to40k", "40to60K", "60to80k", "80to100k", ">100k")), 
    vignette = factor(vignette, levels = c("G1", "G2", "G5", "G9", "G11", 
                                           "L1", "L2", "L5", "L10", "L11"))
  )

#get prior and other variables needed for models
da <- da %>%  
  mutate(
    prior = case_when(
      grepl("G", vignette) ~ xprob - yprob,
      grepl("L", vignette) ~ yprob - xprob
    ),
    direction = case_when(
      grepl("G", vignette) ~ "G",
      grepl("L", vignette) ~ "L"
    )
  )

#get whether passed attn_check or not
da <- da %>% 
  mutate(
    attn_pass = dummyxprob > 50
  )

#### NOW T2

#Get timepoint2 data
db <- read_csv(
  here::here("experiment3", "timepoint2", "data", "exp3b-data.csv"),
  na = c("", "NA", "na")
  )

#WRANGLE 3B

#make factors 
db <- db %>% 
  mutate(
    age_t2 = age,
    gender_t2 = factor(gender),
    income_t2 = factor(income, levels = c("<20k", "20to40k", "40to60K", "60to80k", "80to100k", ">100k")), 
    education_t2 = education,
    datetime_t2 = datetime,
    vignette = factor(vignette, levels = c("G1", "G2", "G5", "G9", "G11", 
                                           "L1", "L2", "L5", "L10", "L11")),
    trialn_t2 = trialn,
    .keep = "unused"
  )


# get ambiguity aversion 
db <- db %>% 
  mutate(
    AA = case_when(
      resp_order == "A" ~ -(response - 4),
      resp_order == "B" ~ response - 4,      
    )
  )

#get whether passed attn_check or not
db <- db %>% 
  mutate(
    attn_pass_t2 = dummyVignetteAnswer > 4
  )

#### COMBINE ### 
dc_all <- da %>% 
  left_join(db, c("part2code" = "subject", "vignette" = "vignette")) %>% 
  rename(part1code = "subject") 

dc <- dc_all %>% 
  dplyr::select(SubjID, gender:income, vignette, direction, prior, conf, AA, attn_pass, attn_pass_t2, trialn,  trialn_t2)

#passed all timepoints that they did data - for LTFU analysis 
dc_pass <- dc %>% 
  filter(attn_pass & (attn_pass_t2 | is.na(attn_pass_t2))) %>% 
  mutate(
    LTFU = attn_pass & is.na(attn_pass_t2)
  )

dc_both <- dc_pass %>% 
  filter(attn_pass & attn_pass_t2)   

```

## Demographic statistics {.active}

Below I report the demographic statistics for the final sample (who completed and passed both timepoints). To see demographic details for each timepoint, see those analyses. 

```{r}
# get basic descriptives before exclusion
demo_d <- dc_both %>% 
  distinct(SubjID, gender, age, education, income) 

```

### Gender

```{r}
demo_d %>% 
  count(gender) %>% 
  arrange(desc(n)) %>% 
  flextable::flextable()

```

###  Age 

```{r}
demo_d %>% 
  ggplot(aes(x = age)) + 
  geom_histogram(fill = "light blue", col = "black") +
  annotate(
    geom = "text", x = 60, y = 20,
    label = paste0("M (SD) = ", round(mean(demo_d$age), 2),
                   " (", round(sd(demo_d$age), 2), ")")
  )

```

### Education (in years)

```{r}
demo_d %>% 
  ggplot(aes(x = education)) + 
  geom_histogram(fill = "light blue", col = "black") +
  annotate(
    geom = "text", x = 20, y = 50,
    label = paste0("M (SD) = ", round(mean(demo_d$education, na.rm = TRUE), 2),
                   " (", round(sd(demo_d$education, na.rm = TRUE), 2), ")")
  )

```

### Income 

```{r}
demo_d %>% 
  count(income) %>% 
  flextable::flextable()

```

# Analysis

## Within-participants (main) analysis

### Plots

```{r}
dc_both %>% 
  ggplot(aes(x = prior, y = AA)) +
  geom_jitter(alpha = 0.25) +
  geom_smooth(method = "lm") + 
  labs(
    title = "Regressing ambiguity aversion onto priors collapsing across vignettes"
  )

## Plot each separately, with correlations too

# get correlations and significance tests for each vignette
cors <- dc_both %>% 
  group_by(vignette) %>% 
  summarise(
    r = cor(prior, AA, method = "spearman"),
    p = cor.test(prior, AA, method = "spearman")$p.value) %>% 
  mutate(
    label = paste0("rho == ", round(r, 2))
    )

# draw plot
dc_both %>% 
  ggplot(aes(x = prior, y = AA, col = vignette)) +
  geom_jitter(alpha = 0.15) +
  geom_smooth(method = "lm", se = FALSE) +
  ggsci::scale_color_d3() +
  facet_wrap(~vignette) +
  theme(legend.position = "none") +
  geom_text(aes(label = label), x = 60, y = 2.9, col = "black", data = cors, fontface = "bold", parse = TRUE) +
  labs(
    title = "Regressing ambiguity aversion onto priors within each vignette",
    caption = "Spearman's correlation coefficient reported due to ordinal nature of AA variable"
  )

# return whole correlation table
cors %>% 
  dplyr::select(-label) %>% 
  mutate(p = round(p,  3)) %>% 
  rename(`$\\rho$` = "r") %>% 
  flextable::flextable() %>% 
  flextable::set_caption("Correlations between Ambiguity Aversion and Prior for each vignette") %>% 
  flextable::add_footer_lines("Spearman's correlation coefficient reported due to ordinal nature of AA variable") %>% 
  ftExtra::colformat_md(part = "all")

```

### Modeling

Bayesian and Frequentist analyses differ slightly on their preferred model, with both having extremely similar . 

The exact model is unclear, but the following is clear: 
- more favourable priors predicts lesser ambiguity aversion
- there is greater ambiguity aversion for 
- greater confidence in prior estimates leads to lesser ambiguity aversion
- models with a small interaction effect between `direction` and `prior`, but these had little effect on model predictions, and were hardly preferred in LOOIC or AIC. 

#### Bayesian Analysis

##### Prior Models

Fit `prior` models

```{r, eval = !priormods_exist, class.source = "fold-show"}
## prior models
mb0 <- brm(ordered(AA) ~ 1 + (1|SubjID) + (1|vignette), data = dc_both, 
           family = cumulative(link = "logit"), cores = 4)

mb_dir <- brm(ordered(AA) ~ 1 + direction + (1|SubjID) + (1|vignette), data = dc_both, 
              family = cumulative(link = "logit"), cores = 4)

mb_prior  <- brm(ordered(AA) ~ 1 + prior +(1|SubjID) + (1|vignette), data = dc_both, 
                 family = cumulative(link = "logit"), cores = 4)

mb_dir_prior  <- brm(ordered(AA) ~ 1 + direction + prior + (1|SubjID) + (1|vignette), data = dc_both, 
                     family = cumulative(link = "logit"), cores = 4)

mb_int  <- brm(ordered(AA) ~ 1 + direction*prior + (1|SubjID) + (1|vignette), data = dc_both, 
               family = cumulative(link = "logit"), cores = 4)

# Save to file so don't have to reanalyse
save(mb0, mb_dir, mb_prior, mb_dir_prior, mb_int, 
     file = "bayesmods_prior.Rdata")

```

Analysing LOOIC shows that model including `direction` and `prior` is the best fit of all the 'prior models'. 

```{r}
# load models, but don't error if they don't exist
try(
 load(file = "bayesmods_prior.Rdata"),
 silent = TRUE
)

# make list of mods
prior_bmods <- list(mb0, mb_dir, mb_prior, mb_dir_prior, mb_int)

tab_bayes_prior <- tibble(
  formula = map_chr(prior_bmods, function(x) x$formula$formula %>% as.character),
  LOOIC_Estimate = map_dbl(prior_bmods, function(x) loo(x)$looic),
  LOOIC_SE = map_dbl(prior_bmods, function(x) loo(x)$se_looic)
)

tab_bayes_prior %>% 
  flextable::flextable() %>% 
  ftExtra::span_header() %>% 
  autofit()

```

<details><summary>Open here to see full details of LOO statistics (and diagnostic checks for Pareto Smoothed Importance Sampling)</summary>

```{r}
map(prior_bmods, loo)
```

</details>
<br></br>

Here are the full details for the models with best fit. First, model with prior and direction WITH interaction. Second, with slightly worse LOOIC, model with independent prior and direction effects. Looking at the models parameters, both have a large role for priors. This model indicates that holding all other effects constant the odds of a responding in with higher Ambiguity Aversion category. This is assumed to be the same odds as we move from each category (-3 , prefer ambiguity to risk ) due to the proportional odds assumption. 


```{r, class.source = "fold-show"}
#best fitting model (JUST) is direction and prior WITH interaction
mb_int %>%  summary() # interaction model will shows strong prior effect
mb_dir_prior %>%  summary()

```

Plot (fixed effects of) both models to see differences in predictions, though. This also shows extremely similar predictions between these two models. 

```{r}
preddat <- expand.grid(prior = -100:100,
            direction = c("G", "L"))

preds_noint <- 
  cbind(preddat, 
        predict(mb_dir_prior, newdata = preddat, re_formula = NA)
        ) %>% 
  pivot_longer(cols = `P(Y = -3)`:`P(Y = 3)`,
               names_to = "level",
               values_to= "prob") %>% 
  mutate(model = "no interaction")

preds_int <- 
  cbind(preddat, 
        predict(mb_int, newdata = preddat, re_formula = NA)
        ) %>% 
  pivot_longer(cols = `P(Y = -3)`:`P(Y = 3)`,
               names_to = "level",
               values_to= "prob") %>% 
  mutate(model = "interaction")

rbind(preds_noint, preds_int) %>% 
  mutate(
    level = factor(level),
    level = fct_relevel(level, c("P(Y = -3)", "P(Y = -2)"))
  ) %>% 
  ggplot(aes(x = prior, col = direction, y = prob)) +
  geom_line() +
  facet_grid(model~level) +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1)
  )


```

##### Confidence Models

Fit `confidence` models

```{r, eval = !confmods_exist, class.source = "fold-show"}
mb_conf  <- brm(ordered(AA) ~ 1 + conf +(1|SubjID) + (1|vignette), data = dc_both, 
                family = cumulative(link = "logit"), cores = 4)
mb_dir_conf  <- brm(ordered(AA) ~ 1 + direction + conf + (1|SubjID) + (1|vignette), data = dc_both, 
                    family = cumulative(link = "logit"), cores = 4)
mb_confint  <- brm(ordered(AA) ~ 1 + direction*conf + (1|SubjID) + (1|vignette), data = dc_both, 
                   family = cumulative(link = "logit"), cores = 4)

# Save to file so don't have to reanalyse
save(mb_conf, mb_dir_conf, mb_confint, 
     file = "bayesmods_conf.Rdata")

```

Analysing LOOIC shows that model including `direction` and `confidence` is the best fit of all the 'confidence models'. 

```{r}
# load models, but don't error if they don't exist
try(
 load(file = "bayesmods_conf.Rdata"),
 silent = TRUE
)

conf_bmods <- list(mb0, mb_dir, mb_conf, mb_dir_conf, mb_confint)

tab_bayes_conf <- tibble(
  formula = map_chr(conf_bmods, function(x) x$formula$formula %>% as.character),
  LOOIC_Estimate = map_dbl(conf_bmods, function(x) loo(x)$looic),
  LOOIC_SE = map_dbl(conf_bmods, function(x) loo(x)$se_looic)
)

tab_bayes_conf %>% 
  flextable::flextable() %>% 
  ftExtra::span_header() %>% 
  autofit()

```

<details><summary>Open here to see full details of LOO statistics (and diagnostic checks for Pareto Smoothed Importance Sampling)</summary>

```{r}
map(conf_bmods, loo)
```

</details>
<br></br>

Here are the full details for the models with best fit.

```{r}
#best fitting model (JUST) is just with confidence (and no direction)
mb_conf %>%  summary()
mb_dir_conf %>%  summary()
mb_confint %>%  summary() # interaction model will shows strong prior effect

```

##### Combined model

Fit `combined` model combining best `prior` and `confidence` models 

```{r, eval = !combmods_exist, class.source = "fold-show"}

## COMBINE FOR BEST FITTING MODEL? 
mb_combined <- brm(ordered(AA) ~ 1 + direction*prior + conf + (1|SubjID) + (1|vignette), data = dc_both,
                   family = cumulative(link = "logit"), cores = 4)
mb_combined_noint <- brm(ordered(AA) ~ 1 + direction + prior + conf + (1|SubjID) + (1|vignette), data = dc_both,
                   family = cumulative(link = "logit"), cores = 4)

# Save to file so don't have to reanalyse
save(mb_combined, mb_combined_noint, file = "bayesmods_comb.Rdata")


```

LOOIC shows that combined  model is preferred to the best 'prior model'. Even though it wasn't pre-registered, I also analysed whether a combined model without any interactions would fit any better. 

```{r}
# load models, but don't error if they don't exist
try(
 load(file = "bayesmods_comb.Rdata"),
 silent = TRUE
)

comb_bmods <- list(mb_int, mb_combined,  mb_combined_noint)

tab_bayes_comb <- tibble(
  formula = map_chr(comb_bmods, function(x) x$formula$formula %>% as.character),
  LOOIC_Estimate = map_dbl(comb_bmods, function(x) loo(x)$looic),
  LOOIC_SE = map_dbl(comb_bmods, function(x) loo(x)$se_looic)
)

tab_bayes_comb %>% 
  flextable::flextable() %>% 
  ftExtra::span_header() %>% 
  autofit()

```
<details><summary>Open here to see full details of LOO statistics (and diagnostic checks for Pareto Smoothed Importance Sampling)</summary>

```{r}
map(comb_bmods, loo)
```

</details>

##### Best fitting Model

Interpreting the parameters:

- For a 1 point more favourable prior, the odds are multiplied by 0.9917 (`exp(-.0083)`), or decrease by 1%. To put this into context given how fine-grained this variable is, for a 10 point more favourable prior, the odds are multiplied by 0.92 (`exp(-.0083)^10`), or decrease by 8%. 
- For a gain vignette compared to a loss vignette, the odds of choosing a more ambiguity aversion option are multiplied by 2.117 (`exp(0.75)`), or increase by 112%. 
- for each confidence rating increase (from not at all to very little, very little to some, so..), the odds of choosing a more higher ambiguity aversion category are multiplied by 1.085 (`exp(0.0816)`). For the whole range of this variable (4), i.e., going from not at all confident to extremely confident, odds are multiplied by 1.386 (`exp(0.0816)^4`).  This is an extremely small effect, and is not 'significant' even though it is in the preferred model. 
- There is an interaction effect in which the effect of prior on ambiguity aversion is stronger (greater absolute magnitude, but still negative) for gain vignettes than for loss vignettes. This is an extremely small effect, and is not 'significant' even though it is in the preferred model. 
 
NB. the analysis of `prior` and `direction` paramaters above are not completely correct given the model includes a `prior*direction` interaction. The only way to really show the effect of paramaters in light of an interaction effect is to plot predictions, which is done below. 

```{r,  class.source = "fold-show"}
#model summary
mb_combined %>% summary()

#fixed effects in more detail
fixef(mb_combined)

#hypothesis tests
hypothesis(mb_combined, "prior < 0")
hypothesis(mb_combined, "directionL < 0")
hypothesis(mb_combined, "directionL:prior < 0")
hypothesis(mb_combined, "conf > 0")
```

Plot (fixed effects of) models to see predictions. 

```{r}

#get predictions
preddat_comb <- expand.grid(prior = -100:100,
            direction = c("G", "L"),
            conf = 0:4)

preds_comb <- 
  cbind(preddat_comb, 
        predict(mb_combined, newdata = preddat_comb, re_formula = NA)
        ) %>% 
  pivot_longer(cols = `P(Y = -3)`:`P(Y = 3)`,
               names_to = "level",
               values_to= "prob") 


#still get  fuzzy estimates -- might need to remodel with larger number of iterations to improve this, but this is somehow nice, as it (inadvertently) shows some of the variance in the point estimates. 

#SHOW FINAL MODEL PREDICTIONS

preds_comb %>% 
  mutate(
    level = factor(level),
    level = fct_relevel(level, c("P(Y = -3)", "P(Y = -2)")),
    conf = as.character(conf)
  ) %>% 
  ggplot(aes(x = prior, col = conf, y = prob)) +
  geom_line(alpha = 0.75) +
  facet_grid(direction~level) +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1),
  ) +
  scale_color_d3(breaks = 0:4, labels = c("None", "Slight", "Moderate", "Very", "Extreme")) +
  labs(
    title = "Plotting fixed effect predictions of best fitting model",
    caption = "Model is AA ~ 1 + direction*prior + conf "
  )

```

#### Frequentist

```{r, class.source = "fold-show"}

## prior models
m0 <- clmm(ordered(AA) ~ 1 + (1|SubjID) + (1|vignette), dc_both)
m_dir <- clmm(ordered(AA) ~ 1 + direction + (1|SubjID) + (1|vignette), dc_both)
m_prior  <- clmm(ordered(AA) ~ 1 + prior +(1|SubjID) + (1|vignette), dc_both)
m_dir_prior  <- clmm(ordered(AA) ~ 1 + direction + prior + (1|SubjID) + (1|vignette), dc_both)
m_int  <- clmm(ordered(AA) ~ 1 + direction*prior + (1|SubjID) + (1|vignette), dc_both)

prior_mods <- list(m0, m_dir, m_prior, m_dir_prior, m_int)

map(prior_mods,  AIC)

#best fitting model (JUST) is direction and prior without interaction
m_dir_prior %>%  summary()
m_int %>%  summary() # interaction model will shows strong prior effect


## conf models ##
m_conf  <- clmm(ordered(AA) ~ 1 + conf +(1|SubjID) + (1|vignette), dc_both)
m_dir_conf  <- clmm(ordered(AA) ~ 1 + direction + conf + (1|SubjID) + (1|vignette), dc_both)
m_confint  <- clmm(ordered(AA) ~ 1 + direction*conf + (1|SubjID) + (1|vignette), dc_both)

conf_mods <- list(m0, m_dir, m_conf, m_dir_conf, m_confint)

map(conf_mods,  AIC)

#best fitting model (JUST) is direction and conf without interaction
m_dir_conf %>%  summary()
m_confint %>%  summary() # interaction model will shows strong prior effect


## COMBINE FOR BEST FITTING MODEL? 
m_combined <- clmm(ordered(AA) ~ 1 + direction + prior + conf + (1|SubjID) + (1|vignette), dc_both)

AIC(m_dir_prior)
AIC(m_combined)

## Combined model is the best 
m_combined %>% summary()

```

## Between-participants analysis

The Between participants analysis broadly replicates from our experiment 2. Both when including and when excluding vignette G1 (classic urn scenario), the best model includes only an overall intercept and paramter for vignette `direction`. In experiment 2,  this was  the result when excluding G1 but not when including it -- perhaps by the changes made to G1 for experiment 3 (removing the introductory phrase 'In a casino'),  we reduced it as such a strongly influential outlier. 

Results and graphs follow. 

### Analysis Including G1 

```{r}
d_btw <- dc_both %>%  
  group_by(direction, vignette) %>% 
  summarise(
    meanAA = mean(AA),
    meanPrior = mean(prior),
    meanConf = mean(conf)
  )

## plot
d_btw  %>% 
  ggplot(aes(x = meanPrior, y = meanAA)) +
  geom_label(aes(label = vignette)) +
  geom_smooth(method = "lm") +
  labs(
    title = "Least Squares regression model with 'prior' parameter but no 'direction' parameter",
    subtitle = "Vignette G1 (Classic Urn vignette) Included"
  )

d_btw  %>% 
  ggplot(aes(x = meanPrior, y = meanAA, col = direction)) +
  geom_label(aes(label = vignette)) +
  moderndive::geom_parallel_slopes(method = "lm", se = FALSE, size = 1, alpha = 0.8) +
  geom_hline(yintercept = 0, linetype = 2, alpha = .8) +
  geom_vline(xintercept = 0, linetype = 2, alpha = .8) +
  annotate(geom = "label", label = "Unfavourable event\nmore likely", x = -10, y = 1.6, fill = "gray95", vjust = "inward") +
  annotate(geom = "label", label = "Favourable event\nmore likely", x = 10, y = 1.6, fill = "gray95", vjust = "inward") +
  annotate(geom = "label", label = "Ambiguity\nAversion", x = -32, y = .75, fill = "gray95", hjust = "inward") +
  annotate(geom = "label", label = "Ambiguity\nSeeking", x = -32, y = -0.3, fill = "gray95", hjust = "inward") +
  labs(
    title = "Least Squares regression model with 'prior' and 'direction' parameter,\nbut no interaction (parallel slopes)",
    subtitle = "Vignette G1 (Classic Urn vignette) Included"
  )


### compare models 
btw_mods <- list()

btw_mods[[1]] <- lm(meanAA ~ 1, data = d_btw)
btw_mods[[2]] <- lm(meanAA ~ 1 + direction, data = d_btw)
btw_mods[[3]] <- lm(meanAA ~ 1 + meanPrior, data = d_btw)
btw_mods[[4]] <- lm(meanAA ~ 1 + direction + meanPrior, data = d_btw)
btw_mods[[5]] <- lm(meanAA ~ 1 + direction*meanPrior, data = d_btw)
btw_mods[[6]] <- lm(meanAA ~ 1 + meanConf, data = d_btw)
btw_mods[[7]] <- lm(meanAA ~ 1 + direction + meanConf, data = d_btw)
btw_mods[[8]] <- lm(meanAA ~ 1 + direction*meanConf, data = d_btw)
btw_mods[[9]] <- lm(meanAA ~ 1 + direction + meanPrior + meanConf, data = d_btw)

# show table 
tibble(
  formula = map_chr(btw_mods, function(x) as.character(x$call)[2]),
  AIC_value = map_dbl(btw_mods, AIC),
  AIC_weight = qpcR::akaike.weights(AIC_value)$weights
) %>% 
  flextable::flextable() %>% 
  ftExtra::span_header() %>% 
  flextable::set_caption("AIC values and AIC weights for between participant models") %>% 
  autofit()

```

### Analysis Excluding G1

```{r}
## Now when remove G1
d_btw_nG1 <- d_btw %>%  
  filter(vignette != "G1")

## plot
d_btw_nG1  %>% 
  ggplot(aes(x = meanPrior, y = meanAA)) +
  geom_label(aes(label = vignette)) +
  geom_smooth(method = "lm") +
  labs(
    title = "Least Squares regression model with 'prior' parameter but no 'direction' parameter",
    subtitle = "Vignette G1 (Classic Urn vignette) excluded"
  )

d_btw_nG1  %>% 
  ggplot(aes(x = meanPrior, y = meanAA, col = direction)) +
  geom_label(aes(label = vignette)) +
  moderndive::geom_parallel_slopes(method = "lm", se = FALSE, size = 1, alpha = 0.8) +
  geom_hline(yintercept = 0, linetype = 2, alpha = .8) +
  geom_vline(xintercept = 0, linetype = 2, alpha = .8) +
  annotate(geom = "label", label = "Unfavourable event\nmore likely", x = -10, y = 1.6, fill = "gray95", vjust = "inward") +
  annotate(geom = "label", label = "Favourable event\nmore likely", x = 10, y = 1.6, fill = "gray95", vjust = "inward") +
  annotate(geom = "label", label = "Ambiguity\nAversion", x = -32, y = .75, fill = "gray95", hjust = "inward") +
  annotate(geom = "label", label = "Ambiguity\nSeeking", x = -32, y = -0.3, fill = "gray95", hjust = "inward") +
  labs(
    title = "Least Squares regression model with 'prior' and 'direction' parameter,\nbut no interaction (parallel slopes)",
    subtitle = "Vignette G1 (Classic Urn vignette) excluded"
  )


## Models
btw_mods_nG1 <- list()

btw_mods_nG1[[1]] <- lm(meanAA ~ 1, data = d_btw_nG1)
btw_mods_nG1[[2]] <- lm(meanAA ~ 1 + direction, data = d_btw_nG1)
btw_mods_nG1[[3]] <- lm(meanAA ~ 1 + meanPrior, data = d_btw_nG1)
btw_mods_nG1[[4]] <- lm(meanAA ~ 1 + direction + meanPrior, data = d_btw_nG1)
btw_mods_nG1[[5]] <- lm(meanAA ~ 1 + direction*meanPrior, data = d_btw_nG1)
btw_mods_nG1[[6]] <- lm(meanAA ~ 1 + meanConf, data = d_btw_nG1)
btw_mods_nG1[[7]] <- lm(meanAA ~ 1 + direction + meanConf, data = d_btw_nG1)
btw_mods_nG1[[8]] <- lm(meanAA ~ 1 + direction*meanConf, data = d_btw_nG1)
btw_mods_nG1[[9]] <- lm(meanAA ~ 1 + direction + meanPrior + meanConf, data = d_btw_nG1)

# show table 
tibble(
  formula = map_chr(btw_mods_nG1, function(x) as.character(x$call)[2]),
  AIC_value = map_dbl(btw_mods_nG1, AIC),
  AIC_weight = qpcR::akaike.weights(AIC_value)$weights
) %>% 
  flextable::flextable() %>% 
  ftExtra::span_header() %>% 
  flextable::set_caption("AIC values and AIC weights for between participant models excluding G1") %>% 
  autofit()


```

## Lost to follow up (LTFU) analysis

There is some evidence that there is a small effect, with those lost to follow up rating the vignette priors to be 2.63 points more favourable than those with followup in the frequentist analysis. However, the Bayesian analysis preferred the null model. Thus, likely indicating that if selection effects exist, they are minor.

### Frequentist modeling

```{r, class.source = "fold-show"}

m0 <- lmer(prior ~ 1 + (1|SubjID) + (1|vignette), dc_pass)
m_ltfu <- lmer(prior ~ 1 + LTFU + (1|SubjID) + (1|vignette), dc_pass)

AIC(m0)
AIC(m_ltfu)

summary(m0)
summary(m_ltfu)

```

### Bayesian modeling

```{r, eval = !LTFUmods_exist, class.source = "fold-show"}
#bayes
m0_bayes <- brm(prior ~ 1 + (1|SubjID) + (1|vignette), 
                data = dc_pass,
                cores = 4,
                #refresh = 0, open_progress = FALSE
                )

m_ltfu_bayes <- brm(prior ~ 1 + LTFU + (1|SubjID) + (1|vignette), 
                  data = dc_pass,
                  cores = 4,
                  #refresh = 0, open_progress = FALSE
                  )

# Save to file so don't have to reanalyse
save(m0_bayes, m_ltfu_bayes, 
     file = "bayesmods_LTFU.Rdata")
```

```{r, class.source = "fold-show"}
# load models, but don't error if they don't exist
try(
 load(file = "bayesmods_LTFU.Rdata"),
 silent = TRUE
)

m0_bayes %>%  summary()
m_ltfu_bayes %>%  summary()

##LOO COMPARE
loo(m0_bayes)
loo(m_ltfu_bayes)

```

## Do order effects affect main relationship between priors and AA?

There were order effects which could have given artificially given rise to the main finding of a negative relationship between favourable priors and ambiguity aversion (as later trials had more favourable priors and less ambiguity aversion -- so each timepoints individual analysis). The following graphical analysis renders this hypothesis unlikely. 

The following graphs, illustrate that this negative relationship persisted for all trial positions when considering trial position for the AA and prior ratings univariately.

```{r}
dc_both %>% 
  ggplot(aes(x = prior, y = AA)) +
  geom_jitter(alphpa = 0.5) +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~trialn) +
  labs(
    title = "checking the relationship between prior and AA\nfor different trial positions for prior rating"
  )


dc_both %>% 
  ggplot(aes(x = prior, y = AA)) +
  geom_jitter(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~trialn_t2) +
  labs(
    title = "checking the relationship between prior and AA\nfor different trial positions for AA rating"
  )


```

In addition, the effect persisted in a majority of cases when conditioning on both the AA and prior rating bivariately (however, note, here than sample sizes are small, so more noise is to be expected between position-groups given law of large numbers), and without a clear pattern (which would be expected if relationship was an artifact of trial positions) in which the relationship is much more likely for late-AA-trial-position/late-prior-trial-position combinations, much less likely for early-AA-trial-position/early-prior-trial-position combinations, and middling for other position combinations. Thus, it appears that the effect is NOT a mere artifact of the order in our experimental design. 

```{r fig.height= 7, fig.width=7}

dc_both %>% 
  ggplot(aes(x = prior, y = AA)) +
  geom_jitter(alpha =  0.5) +
  geom_smooth(method = "lm", se = FALSE) +
  facet_grid(trialn_t2~trialn) +
  labs(
    title = "Checking the relationship between prior and AA\nfor different trial positions for both prior andn AA rating",
    subtitle = "Trial position for prior rating - horizontal, for AA rating - vertical"
  ) +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1)
  )


```


